{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/ncarkaci/TDKDictionaryCrawler/master/ortak_kelimeler.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ortak_kelimeler.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text = text.replace(\"\\n\",\"\")\n",
    "ids_list = list(set(long_text))\n",
    "len(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(97, 'a'),\n",
       " (98, 'b'),\n",
       " (99, 'c'),\n",
       " (100, 'd'),\n",
       " (101, 'e'),\n",
       " (102, 'f'),\n",
       " (103, 'g'),\n",
       " (104, 'h'),\n",
       " (105, 'i'),\n",
       " (106, 'j'),\n",
       " (107, 'k'),\n",
       " (108, 'l'),\n",
       " (109, 'm'),\n",
       " (110, 'n'),\n",
       " (111, 'o'),\n",
       " (112, 'p'),\n",
       " (114, 'r'),\n",
       " (115, 's'),\n",
       " (116, 't'),\n",
       " (117, 'u'),\n",
       " (118, 'v'),\n",
       " (121, 'y'),\n",
       " (122, 'z'),\n",
       " (231, 'ç'),\n",
       " (246, 'ö'),\n",
       " (252, 'ü'),\n",
       " (287, 'ğ'),\n",
       " (305, 'ı'),\n",
       " (351, 'ş')]"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_char_pairs = sorted([(ord(c),c) for c in ids_list])\n",
    "ordinal_char_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi = {c:i for i,(o,c) in enumerate(ordinal_char_pairs)}\n",
    "itoc =  {i:c for i,(o,c) in enumerate(ordinal_char_pairs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi['.']=len(ctoi)\n",
    "itoc[len(itoc)]='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input:str):\n",
    "    return [ctoi[c] for c in input]\n",
    "\n",
    "def decode(ids):\n",
    "    return \"\".join([itoc[i] for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert decode(encode(\"zemberek\"))=='zemberek'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.probs = None\n",
    "        self.all_probs = None\n",
    "\n",
    "    def train(self, words):\n",
    "        ids_list = get_data(words, n=self.n)\n",
    "\n",
    "        counts = count(ids_list, n=self.n)\n",
    "\n",
    "        counts = counts.float() + 1e-10  # smoothing\n",
    "\n",
    "        probs = counts / counts.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        loss = -probs[tuple(ids_list.T)].log().mean()\n",
    "        print(f\"loss: {loss.item()}\")\n",
    "\n",
    "        self.all_probs = [probs]\n",
    "\n",
    "        counts_ = counts\n",
    "        for _ in range(self.n-2):\n",
    "            counts_ = counts_.sum(dim=-1)\n",
    "            probs_ = counts_ / counts_.sum(dim=-1, keepdim=True)\n",
    "            self.all_probs.append(probs_)\n",
    "\n",
    "        self.probs = probs\n",
    "\n",
    "    def generate(self):\n",
    "        chars = [ctoi['.']]\n",
    "        \n",
    "        while True:\n",
    "            back_idx = -min(len(chars), len(self.all_probs))\n",
    "            probs = self.all_probs[back_idx]\n",
    "\n",
    "            ids = chars[back_idx:]\n",
    "            p = probs[tuple(ids)]\n",
    "\n",
    "            assert p.shape == (30,)\n",
    "\n",
    "            new_char = torch.multinomial(p, 1, replacement=True)\n",
    "\n",
    "            new_char = new_char.item()\n",
    "\n",
    "            if new_char == ctoi['.']:\n",
    "                return decode(chars[1:])\n",
    "            \n",
    "            chars.append(new_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NGram(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.522550344467163\n"
     ]
    }
   ],
   "source": [
    "nn.train(words)\n",
    "# loss: 2.522550344467163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(nn.all_probs) == 1\n",
    "assert nn.all_probs[-1].shape == (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "n3 = NGram(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.0314273834228516\n"
     ]
    }
   ],
   "source": [
    "n3.train(words)\n",
    "# loss: 2.0314273834228516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(n3.all_probs) == 2\n",
    "assert n3.all_probs[-1].shape == (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "n4 = NGram(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5213545560836792\n"
     ]
    }
   ],
   "source": [
    "n4.train(words)\n",
    "# loss: 1.5213545560836792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atettı\n",
      "ik\n",
      "öncırısörarsı\n",
      "kakl\n",
      "satsabiçinorekom\n",
      "bil\n",
      "stlllıdaşapek\n",
      "k\n",
      "s\n",
      "ir\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(35)\n",
    "for i in range(10):\n",
    "    print(nn.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atettı\n",
      "ik\n",
      "ölülhası\n",
      "arsız\n",
      "akl\n",
      "satsabiliyonuk\n",
      "müttırmaklak\n",
      "düğmek\n",
      "kor\n",
      "ih\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(35)\n",
    "for i in range(10):\n",
    "    print(n3.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ateştirik\n",
      "ölümsesuraksız\n",
      "aklata\n",
      "sabuçunutukla\n",
      "biliktenleşme\n",
      "pekleşmek\n",
      "yoğuk\n",
      "poloji\n",
      "şantık\n",
      "çarkeci\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(35)\n",
    "for i in range(10):\n",
    "    print(n4.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
